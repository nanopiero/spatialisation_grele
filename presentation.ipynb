{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2666ea13-a0b5-42ba-ba46-8624ed2cb995",
      "metadata": {
        "id": "2666ea13-a0b5-42ba-ba46-8624ed2cb995"
      },
      "source": [
        "# Atelier 1 : Denoising parfaitement supervisé"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pour commencer : aller dans éxecution/modifier le type d'exécution et vérifier\n",
        "# que CPU est bien coché (on n'a pas besoin de plus pour l'instant)\n",
        "\n",
        "# Imports des bibliothèques utiles\n",
        "# pour l'IA\n",
        "import torch\n",
        "# pour les maths\n",
        "import numpy as np\n",
        "# pour afficher des images et des courbes\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "6n2YmAgdpTfY"
      },
      "id": "6n2YmAgdpTfY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c81b943d-4b2f-4314-9f4a-d53631db4cce",
      "metadata": {
        "id": "c81b943d-4b2f-4314-9f4a-d53631db4cce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9093213-e803-4961-fea7-30a8f68d28c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'spatialisation_grele'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3/3), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/nanopiero/spatialisation_grele"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "560c719f-acc0-400d-a30a-deb84e2a6085",
      "metadata": {
        "id": "560c719f-acc0-400d-a30a-deb84e2a6085",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "674d0b2a-70a0-4351-d9d6-5771e3f16bb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apprentissage.ipynb  presentation.ipynb\n"
          ]
        }
      ],
      "source": [
        "! ls spatialisation_grele"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A. Découverte du problème"
      ],
      "metadata": {
        "id": "mAsAdLwzz3MQ"
      },
      "id": "mAsAdLwzz3MQ"
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Le 25/04/2024\n",
        "@author: lepetit\n",
        "#fonctions utiles pour l'atelier PREAC\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from random import randint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from random import randint\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n"
      ],
      "metadata": {
        "id": "RUlGlUnAPCho"
      },
      "id": "RUlGlUnAPCho",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Le 03/06/2024\n",
        "@author: lepetit\n",
        "# fonctions utiles pour la génération\n",
        "# de données à fusionner\n",
        "\"\"\"\n",
        "from random import randint\n",
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "##############################\n",
        "########## with JIT ##########\n",
        "##############################\n",
        "from numba import jit\n",
        "from numpy.random import randint\n",
        "\n",
        "\n",
        "@jit(nopython=True)\n",
        "def pseudo_meshgrid(size):\n",
        "  b = np.arange(0, size).repeat(size).reshape(1,size,size)\n",
        "  a = np.transpose(b, (0,2,1))\n",
        "  return  a.astype(np.float32), b.astype(np.float32)\n",
        "\n",
        "@jit(nopython=True)\n",
        "def generate_cell_and_hail_characteristics(nsteps, size, pseudo_size, centered,\n",
        "                                           relative_advection_speed,\n",
        "                                           smajor_axis_k=None,\n",
        "                                           eccentricity_k=None,\n",
        "                                           theta_increment=None,\n",
        "                                           intensity=None\n",
        "                                           ):\n",
        "    # Choose k\n",
        "    if centered:\n",
        "      k = np.random.randint(nsteps//4, nsteps-nsteps//4)\n",
        "    else:\n",
        "      k = np.random.randint(2, nsteps-2)\n",
        "\n",
        "    # Generate the kth major_axis, minor_axis,  center, rotation, focus, and radius\n",
        "    if smajor_axis_k is None:\n",
        "      smajor_axis_k = np.random.uniform(5, 20)\n",
        "\n",
        "    if centered:\n",
        "      center_k = np.array([size // 2, size //2 ]).astype(np.float32)\n",
        "    else:\n",
        "      center_k = (3*smajor_axis_k + (size - 3*smajor_axis_k)*np.random.random(2)).astype(np.float32)\n",
        "\n",
        "    if eccentricity_k is None:\n",
        "      eccentricity_k = 0.2 + 0.8 * np.random.rand()\n",
        "\n",
        "    theta_k = np.pi * np.random.rand()\n",
        "\n",
        "    # Generate advection speed and radius increment\n",
        "    if centered:\n",
        "      relative_advection_speed = 2*np.random.normal(0, 3, 2).astype(np.float32)\n",
        "      advection_speed = np.zeros(2).astype(np.float32)\n",
        "    else:\n",
        "      advection_speed = (2*np.random.normal(0, 3, 2) - relative_advection_speed).astype(np.float32)\n",
        "\n",
        "    smajor_axis_increment = np.random.normal(0, 1/nsteps)\n",
        "    eccentricity_increment = 2/nsteps * np.random.rand()\n",
        "\n",
        "    if theta_increment is None:\n",
        "      theta_increment = np.random.normal(0, np.pi/nsteps)\n",
        "\n",
        "    # Fill centers and radii arrays\n",
        "    arange_nsteps = np.arange(nsteps).astype(np.float32)\n",
        "    abs_centers = center_k[0] + (arange_nsteps - k) * advection_speed[0]\n",
        "    ord_centers = center_k[1] + (arange_nsteps - k) * advection_speed[1]\n",
        "\n",
        "    smajor_axis = smajor_axis_k + (arange_nsteps - k) * smajor_axis_increment\n",
        "    smajor_axis[smajor_axis <= 0] = 0.\n",
        "    eccentricity = eccentricity_k  +  (arange_nsteps - k) * eccentricity_increment\n",
        "    eccentricity[eccentricity <= 0] = -1*eccentricity[eccentricity <= 0]\n",
        "    eccentricity[eccentricity >= 0.9] = 0.9\n",
        "    theta = theta_k  +  (np.arange(nsteps).astype(np.float32) - k) * theta_increment\n",
        "\n",
        "    # Get intensity of the cell and hail characteristics:\n",
        "    ratio_radius = 0.3\n",
        "    if intensity is None:\n",
        "      intensity = np.random.uniform(0.3,0.8)\n",
        "\n",
        "    radius = ratio_radius * eccentricity * smajor_axis\n",
        "    hail_steps = (intensity > 0.5) * (theta_increment <= 0) * (radius > 2) * (radius < 4)\n",
        "    hail_size = 10/(size**2) * np.pi * smajor_axis**2 * np.sqrt(1 - eccentricity**2) # hail size prop to the area\n",
        "\n",
        "    return abs_centers, ord_centers, smajor_axis, eccentricity, \\\n",
        "           theta, theta_increment, intensity, hail_steps, hail_size, radius\n",
        "\n",
        "\n",
        "@jit(nopython=True)\n",
        "def closest_nonzero_index(x: np.array) -> int:\n",
        "    # Ensure x is a 1D tensor\n",
        "\n",
        "    D = x.shape[0]\n",
        "    mid_index = D // 2\n",
        "\n",
        "    # Find all non-zero indices\n",
        "    nonzero_indices = np.nonzero(x)[0]\n",
        "\n",
        "    # If there are no non-zero elements, return -1 or handle as needed\n",
        "    if len(nonzero_indices) == 0:\n",
        "        return -1\n",
        "\n",
        "    # Find the non-zero index closest to D//2\n",
        "    print(nonzero_indices)\n",
        "    distances = np.abs(nonzero_indices - mid_index)\n",
        "    closest_index = nonzero_indices[np.argmin(distances)].item()\n",
        "    return closest_index\n",
        "\n",
        "import numpy as np\n",
        "from numba import njit\n",
        "\n",
        "\n",
        "\n",
        "#@njit\n",
        "def select_random_nonzero_pixel(x):\n",
        "    # Find all non-zero indices\n",
        "    non_zero_indices = np.argwhere(x != 0)\n",
        "\n",
        "    # If there are no non-zero elements, return an array of zeros\n",
        "    if len(non_zero_indices) == 0:\n",
        "        return np.zeros_like(x)\n",
        "\n",
        "    # Select a random index from the non-zero indices\n",
        "    random_index = non_zero_indices[np.random.randint(len(non_zero_indices))]\n",
        "\n",
        "    return random_index\n",
        "\n",
        "#@jit(nopython=True)\n",
        "def ground_truth_to_reports(two_circles, centered, freq_reports, toss=False):\n",
        "  if centered and toss: # at least one report\n",
        "    when_hail = np.sum(two_circles, axis=(1,2)) > 0\n",
        "    where_report = closest_nonzero_index(when_hail)\n",
        "    random_index = select_random_nonzero_pixel(two_circles[where_report])\n",
        "    value = two_circles[where_report, random_index[0], random_index[1]].item()\n",
        "\n",
        "  thresh = 0.\n",
        "  reports = np.random.binomial(1, freq_reports, two_circles.shape).astype(np.float32)\n",
        "  reports *= two_circles\n",
        "\n",
        "  if centered and toss:\n",
        "    two_circles[where_report, random_index[0], random_index[1]] = value\n",
        "\n",
        "  return reports.sum(axis=0)\n",
        "\n",
        "\n",
        "\n",
        "#@jit(nopython=True)\n",
        "def simu_moving_ellipse(image, reports, a, b,\n",
        "                        pseudo_size,\n",
        "                        stratification=None,\n",
        "                        centered=False, relative_advection_speed=np.zeros(2),\n",
        "                        add_target=True,\n",
        "                        freq_occurrence=0.5,\n",
        "                        freq_reports=0.5):\n",
        "\n",
        "  nsteps, nchannels, size, _ = image.shape\n",
        "\n",
        "  if stratification is None:\n",
        "    abs_centers, ord_centers, smajor_axis, eccentricity, \\\n",
        "      theta, theta_increment, intensity, hail_steps, hail_size, radius = \\\n",
        "      generate_cell_and_hail_characteristics(nsteps, size, pseudo_size, centered, relative_advection_speed)\n",
        "\n",
        "  elif stratification == 'occurrence':\n",
        "    toss = (np.random.rand(1) < freq_occurrence).item()\n",
        "    if toss:\n",
        "      ratio_radius = 0.3\n",
        "      hail_step_k = False\n",
        "      while not hail_step_k:\n",
        "        smajor_axis_k = np.random.uniform(5, 20)\n",
        "        eccentricity_k = 0.2 + 0.8 * np.random.rand()\n",
        "        enhancer_hail_k = ratio_radius * eccentricity_k * smajor_axis_k\n",
        "        hail_step_k = (enhancer_hail_k < 4) * (enhancer_hail_k > 2)\n",
        "      theta_increment = - np.abs(np.random.normal(0, np.pi/nsteps))\n",
        "      intensity = np.random.uniform(0.5, 0.8)\n",
        "\n",
        "      abs_centers, ord_centers, smajor_axis, eccentricity, \\\n",
        "        theta, theta_increment, intensity, hail_steps, hail_size, radius = \\\n",
        "        generate_cell_and_hail_characteristics(nsteps, size, pseudo_size, centered,\n",
        "                                               relative_advection_speed,\n",
        "                                               smajor_axis_k=smajor_axis_k,\n",
        "                                               eccentricity_k=eccentricity_k,\n",
        "                                               theta_increment=theta_increment,\n",
        "                                               intensity=intensity\n",
        "                                               )\n",
        "    else:\n",
        "      hail_steps_sum = 1.\n",
        "      while hail_steps_sum != 0.:\n",
        "        abs_centers, ord_centers, smajor_axis, eccentricity, \\\n",
        "          theta, theta_increment, intensity, hail_steps, hail_size, radius = \\\n",
        "          generate_cell_and_hail_characteristics(nsteps, size, pseudo_size, centered,\n",
        "                                                relative_advection_speed)\n",
        "        hail_steps_sum = hail_steps.sum()\n",
        "\n",
        "\n",
        "    # print(toss, ' steps :', hail_steps, ' sizes :', hail_size, 'theta inc', theta_increment, 'intensity', intensity, 'radius', radius)\n",
        "\n",
        "  elif stratification == 'size':\n",
        "    pass\n",
        "\n",
        "  # Make the cells:\n",
        "  delta_abs_interfocus = eccentricity * smajor_axis * np.cos(theta)\n",
        "  delta_ord_interfocus = eccentricity * smajor_axis * np.sin(theta)\n",
        "\n",
        "  abs_focus1 = abs_centers + delta_abs_interfocus\n",
        "  ord_focus1 = ord_centers + delta_ord_interfocus\n",
        "  abs_focus2 = abs_centers - delta_abs_interfocus\n",
        "  ord_focus2 = ord_centers - delta_ord_interfocus\n",
        "\n",
        "  square_distances_to_focus1 = (a - abs_focus1.reshape((nsteps, 1, 1)))**2 + \\\n",
        "                         (b - ord_focus1.reshape((nsteps, 1, 1)))**2\n",
        "  square_distances_to_focus2 = (a - abs_focus2.reshape((nsteps, 1, 1)))**2 + \\\n",
        "                         (b - ord_focus2.reshape((nsteps, 1, 1)))**2\n",
        "\n",
        "  sum_distances = np.sqrt(square_distances_to_focus1) + np.sqrt(square_distances_to_focus2)\n",
        "  ellipses =  1. * (sum_distances < 1.25*2*smajor_axis.reshape(nsteps, 1, 1))\n",
        "\n",
        "  # apply a random intensity\n",
        "  ellipses *= intensity\n",
        "  image[:,0] = image[:,0] + ellipses\n",
        "\n",
        "  # Make ground truth\n",
        "  # print('add_target ', add_target)\n",
        "\n",
        "  if (intensity > 0.5) and (theta_increment <= 0) and add_target:\n",
        "\n",
        "    radius = radius.reshape((nsteps, 1, 1))\n",
        "    den = 1/radius**2\n",
        "    two_circles = (radius**2 - square_distances_to_focus1) * den * (square_distances_to_focus1 < radius**2) \\\n",
        "               + (radius**2 - square_distances_to_focus2) * den * (square_distances_to_focus2 < radius**2)\n",
        "    two_circles *= hail_steps.reshape((nsteps, 1, 1))\n",
        "    # print('add_target and max ', add_target, two_circles.max())\n",
        "    # hail size prop to the area :\n",
        "    two_circles *= hail_size.reshape((nsteps, 1, 1))\n",
        "    reports += ground_truth_to_reports(two_circles, centered, freq_reports, toss=True)\n",
        "\n",
        "\n",
        "  return image, reports, relative_advection_speed\n",
        "\n",
        "\n",
        "\n",
        "@jit(nopython=True)\n",
        "def resize_channel(channel, new_size):\n",
        "    x = np.linspace(0, 1, channel.shape[0])\n",
        "    y = np.linspace(0, 1, channel.shape[1])\n",
        "    x_new = np.linspace(0, 1, new_size)\n",
        "    y_new = np.linspace(0, 1, new_size)\n",
        "    return np.interp(x_new[:, None] + y_new[None, :], x, np.interp(y_new, y, channel))\n",
        "\n",
        "#@jit(nopython=True)\n",
        "def spatialized_gt(ndiscs=5, size=64, pseudo_size=None,\n",
        "                   nsteps=60, stratification=None,\n",
        "                   centered=False, freq_occurrence=0.5,\n",
        "                  freq_reports=0.5):\n",
        "\n",
        "  if pseudo_size is None:\n",
        "    pseudo_size = size\n",
        "\n",
        "  image = np.zeros((nsteps, 2, size, size)).astype(np.float32)\n",
        "  reports = np.zeros((2, size, size)).astype(np.float32)\n",
        "  a, b = pseudo_meshgrid(size)\n",
        "\n",
        "  if centered:\n",
        "    image, reports, relative_advection_speed0 = simu_moving_ellipse(image, reports, a, b,\n",
        "                                                           pseudo_size,\n",
        "                                                           stratification,\n",
        "                                                           centered=True,\n",
        "                                                           freq_occurrence=freq_occurrence,\n",
        "                                                           freq_reports=freq_reports\n",
        "                                                           )\n",
        "    for i in range(ndiscs - 1):\n",
        "      image, reports, _ = simu_moving_ellipse(image, reports, a, b,\n",
        "                                     pseudo_size,\n",
        "                                     centered=False,\n",
        "                                     relative_advection_speed=relative_advection_speed0,\n",
        "                                     add_target=False)\n",
        "  else:\n",
        "    image, reports, relative_advection_speed0 = simu_moving_ellipse(image, reports, a, b,\n",
        "                                                           pseudo_size,\n",
        "                                                           stratification=\"occurrence\",\n",
        "                                                           centered=False,\n",
        "                                                           freq_occurrence=freq_occurrence,\n",
        "                                                           freq_reports=freq_reports\n",
        "                                                           )\n",
        "    for i in range(ndiscs - 1):\n",
        "      image, reports, _ = simu_moving_ellipse(image, reports, a, b,\n",
        "                                              pseudo_size,\n",
        "                                              stratification,\n",
        "                                              freq_occurrence=freq_occurrence,\n",
        "                                              freq_reports=freq_reports)\n",
        "  return image, reports\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##############################\n",
        "########## Datasets ##########\n",
        "##############################\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class HailDataset(Dataset):\n",
        "    def __init__(self, length_dataset=6400, centered=True, freq_reports=0.01):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "              I need a pytorch dataset that will simply embed two numpy function that generates random tensors.\n",
        "              These functions, called spatialized_gt and create_cmls_filter are @jit decorated.\n",
        "        \"\"\"\n",
        "        self.length_dataset = length_dataset\n",
        "        self.centered = centered\n",
        "        self.ndiscs = 4\n",
        "        self.pseudo_size = 172\n",
        "        self.nsteps = 12\n",
        "\n",
        "        if centered:\n",
        "          self.stratification ='occurrence'\n",
        "          self.size_image = 64\n",
        "        else:\n",
        "          self.stratification = None\n",
        "          self.size_image = 172\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length_dataset\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, reports = spatialized_gt(ndiscs=self.ndiscs,\n",
        "                               size=self.size_image,\n",
        "                               pseudo_size=self.pseudo_size,\n",
        "                               nsteps=self.nsteps,\n",
        "                               stratification=self.stratification,\n",
        "                               centered=self.centered,\n",
        "                               freq_reports=self.freq_reports\n",
        "                               )\n",
        "\n",
        "        # image = spatialized_gt(ndiscs=4, size=64, pseudo_size=172, nsteps=12, stratification='occurrence', centered=True)\n",
        "        # image = spatialized_gt(ndiscs=4, size=172, pseudo_size=172, nsteps=12, stratification=None, centered=False)\n",
        "\n",
        "        return image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##############################\n",
        "########## on GPU   ##########\n",
        "##############################\n",
        "\n",
        "\n",
        "def generate_indices_rows_and_columns(images, npoints):\n",
        "  bs, nsteps, S, _ = images.shape\n",
        "  weights = torch.ones(S**2).expand(bs, -1).to(images.device)\n",
        "  indices = torch.multinomial(weights, num_samples=npoints, replacement=False) #.to(images.device)\n",
        "\n",
        "  # Calculate coordinates from indices\n",
        "  rows = indices // S\n",
        "  cols = indices % S\n",
        "\n",
        "  # Gather the values from these indices for all images\n",
        "  indices = indices.unsqueeze(dim=1).repeat([1,nsteps,1])\n",
        "  return indices, rows, cols\n",
        "\n",
        "\n",
        "def indices_to_sampled_values(images, indices):\n",
        "  bs, nsteps, S, _ = images.shape\n",
        "  flat_images = images.view(bs, nsteps, S * S)\n",
        "\n",
        "  # Gather the values from these indices for all images\n",
        "  sampled_values = torch.gather(flat_images, 2, indices)\n",
        "  return sampled_values\n",
        "\n",
        "\n",
        "def get_point_measurements(rows, cols, sampled_values, S=64):\n",
        "  # Normalize coordinates to be between 0 and 1\n",
        "  ys = (1 - rows.float()/S) - 1/(2*S)\n",
        "  xs = cols.float()/S + 1/(2*S)\n",
        "\n",
        "  # Stack the normalized coordinates with the values\n",
        "  point_measurements = torch.cat((xs.unsqueeze(1),\n",
        "                                  ys.unsqueeze(1),\n",
        "                                  sampled_values), dim=1)\n",
        "  return point_measurements\n",
        "\n",
        "\n",
        "def point_gt(images, ind_row_col_sampval=None, npoints=10, use_fcn=False, split=None): # nb_pluvios_ Split: (n0,n1,n2,..., nr). rq : n_points = Sum ni\n",
        "  bs, nsteps, S, _ = images.shape\n",
        "\n",
        "  if ind_row_col_sampval is None:\n",
        "\n",
        "      indices, rows, cols = generate_indices_rows_and_columns(images, npoints)\n",
        "      sampled_values = indices_to_sampled_values(images, indices)\n",
        "\n",
        "  else:\n",
        "      indices, rows, cols, sampled_values = ind_row_col_sampval\n",
        "\n",
        "  if split is None:\n",
        "    point_measurements = get_point_measurements(rows, cols, sampled_values, S)\n",
        "\n",
        "    if not use_fcn:\n",
        "      return point_measurements, None, (indices, rows, cols)\n",
        "\n",
        "    else:\n",
        "      # Difference with point_gt:\n",
        "      point_measurements_fcn = -0.1 * torch.ones(images.numel(), device=images.device)\n",
        "      indices_batch = torch.arange(bs).repeat(60)\n",
        "      # indice du premier élément de la i ème image pour le premier time step dans images.flatten()\n",
        "      idx_i000=(torch.arange(bs, device = images.device) * nsteps).view(bs,1).expand(bs,nsteps)\n",
        "      # indices du premier élément de la i ème image pour le premier time step j dans images.flatten()\n",
        "      idx_ij00=idx_i000 + torch.arange(nsteps, device = images.device).view(1,nsteps).expand(bs,nsteps)\n",
        "      # indices à conserver :\n",
        "      idx_ijkl = S**2 * idx_ij00.unsqueeze(-1) + indices\n",
        "      point_measurements_fcn[idx_ijkl.flatten()] = sampled_values.flatten()\n",
        "\n",
        "      point_measurements_fcn = point_measurements_fcn.view(bs, nsteps, S, S)\n",
        "\n",
        "      return point_measurements, point_measurements_fcn, (indices, rows, cols)\n",
        "\n",
        "  # splitting\n",
        "  else:\n",
        "    pos = 0\n",
        "    splitted_point_measurements = []\n",
        "    for np in split:\n",
        "      point_measurements = get_point_measurements(rows[:, pos:pos + np],\n",
        "                                                  cols[:, pos:pos + np],\n",
        "                                                  sampled_values[:, :, pos:pos + np],\n",
        "                                                  S)\n",
        "\n",
        "      splitted_point_measurements.append((point_measurements,\n",
        "                                          None,\n",
        "                                          (indices[:, :, pos:pos + np], rows[:,pos:pos + np], cols[:, pos:pos + np])))\n",
        "      pos += np\n",
        "\n",
        "    if not use_fcn :\n",
        "        return splitted_point_measurements\n",
        "\n",
        "    else :\n",
        "      pos = 0\n",
        "      splitted_point_measurements_fcn = []\n",
        "\n",
        "      for i, np in enumerate(split):\n",
        "        split_indices = indices[:, :, pos:pos + np]\n",
        "\n",
        "        # Difference with point_gt:\n",
        "        point_measurements_fcn = -0.1 * torch.ones(images.numel(), device=images.device)\n",
        "        indices_batch = torch.arange(bs).repeat(60)\n",
        "        # indice du premier élément de la i ème image pour le premier time step dans images.flatten()\n",
        "        idx_i000=(torch.arange(bs, device = images.device) * nsteps).view(bs,1).expand(bs,nsteps)\n",
        "        # indices du premier élément de la i ème image pour le premier time step j dans images.flatten()\n",
        "        idx_ij00=idx_i000 + torch.arange(nsteps, device = images.device).view(1,nsteps).expand(bs,nsteps)\n",
        "        # indices à conserver :\n",
        "        idx_ijkl = S**2 * idx_ij00.unsqueeze(-1) + split_indices\n",
        "        point_measurements_fcn[idx_ijkl.flatten()] = sampled_values[:, :, pos:pos + np].flatten()\n",
        "\n",
        "        splitted_point_measurements_fcn.append((splitted_point_measurements[i][0], point_measurements_fcn.view(bs, nsteps, S, S),\n",
        "                                                (split_indices, rows[:,pos:pos + np], cols[:, pos:pos + np])))\n",
        "        pos += np\n",
        "\n",
        "      return splitted_point_measurements_fcn\n"
      ],
      "metadata": {
        "id": "Lzbg0J1ChdrG"
      },
      "id": "Lzbg0J1ChdrG",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "def plot_images(images, ground_truth, reports):\n",
        "    # Set up the figure with GridSpec\n",
        "    fig = plt.figure(figsize=(18, 20))\n",
        "    gs = gridspec.GridSpec(6, 5, width_ratios=[1, 1, 1, 1, 2])  # Last column twice as wide\n",
        "\n",
        "    # Manually create axes array for uniform handling as before\n",
        "    axs = [fig.add_subplot(gs[i, j]) for i in range(6) for j in range(5)]\n",
        "\n",
        "    # Hide all primary spines and ticks\n",
        "    for ax in axs:\n",
        "        for spine in ax.spines.values():\n",
        "            spine.set_visible(False)\n",
        "        ax.tick_params(axis='both', which='both', left=False, right=False, top=False, bottom=False, labelleft=False, labelbottom=False)\n",
        "\n",
        "    # Image and noisy image plots\n",
        "    for i in range(3):\n",
        "        image_indices = [4*i, 4*i+1, 4*i+2, 4*i+3]\n",
        "        for j in range(4):\n",
        "            ax = axs[2*i*5 + j]\n",
        "            img = images[image_indices[j]]\n",
        "            # img_normalized = (img - np.min(img)) / (np.max(img) - np.min(img) + 0.000001)\n",
        "            ax.imshow(img, cmap='gray', aspect=1, vmin=0, vmax=1)\n",
        "            ax.axis('off')\n",
        "            ax = axs[(2*i + 1)*5  + j]\n",
        "            img = ground_truth[image_indices[j]]\n",
        "            # img_normalized = (img - np.min(img)) / (np.max(img) - np.min(img) + 0.000001)\n",
        "            ax.imshow(img, cmap='gray', aspect=1, vmin=0, vmax=1)\n",
        "            ax.axis('off')\n",
        "    \"\"\"\n",
        "    # Point and Segment measurements plots\n",
        "    for row in range(12):\n",
        "        ax_main = axs[row * 7 + 6]  # Last column in each row\n",
        "        if row < 2:  # First two rows for point measurements\n",
        "            for idx in range(3) if row == 0 else range(2):\n",
        "                ax = ax_main.inset_axes([0, 1 - (idx+1)/3, 1, 1/3])\n",
        "                ax.plot(point_measurements[2:, idx + row*3], marker='.', markevery=(4, 5), markeredgewidth=2, markeredgecolor='black')\n",
        "                label = f\"Pluvio {idx+1 + row*3}\"\n",
        "                ax.set_ylim([-0.1, 1.5])\n",
        "                coord1 = f\"x={point_measurements[0, idx + row*3]:.2f}\"  # First coordinate on a new line\n",
        "                coord2 = f\"y={point_measurements[1, idx + row*3]:.2f}\"  # Second coordinate on another new line\n",
        "                full_label = f\"{label}\\n{coord1}\\n{coord2}\"  # Combine into one string with two newlines\n",
        "                ax.set_ylabel(full_label, rotation=0, labelpad=0, fontsize=6)\n",
        "                ax.yaxis.set_label_coords(0.05, 0.4)\n",
        "                ax.tick_params(axis='both', which='both', left=False, bottom=False, labelleft=False, labelbottom=False)\n",
        "                for spine in ax.spines.values():\n",
        "                    spine.set_visible(False)\n",
        "\n",
        "        elif 2 <= row < 6:  # Next four rows for segment measurements\n",
        "            for idx in range(3):\n",
        "                actual_idx = 3 * (row - 2) + idx\n",
        "                if actual_idx < 10:  # Ensure we don't exceed the 10 graphs\n",
        "                    ax = ax_main.inset_axes([0, 1 - (idx+1)/3, 1, 1/3])\n",
        "                    ax.plot(segment_measurements[4:, actual_idx], marker='.', markevery=(4, 5), markeredgewidth=1, markeredgecolor='black')\n",
        "                    ax.set_ylim([-0.1, 1.5])\n",
        "                    label = f\"CML {actual_idx+1}\"\n",
        "                    coord_text = f\"x1={segment_measurements[0, actual_idx]:.2f}, y1={segment_measurements[1, actual_idx]:.2f}\\nx2={segment_measurements[2, actual_idx]:.2f}, y2={segment_measurements[3, actual_idx]:.2f}\"\n",
        "                    full_label = f\"{label}\\n{coord_text}\"\n",
        "                    ax.set_ylabel(full_label, rotation=0, labelpad=0, fontsize=6)\n",
        "                    ax.yaxis.set_label_coords(0.05, 0.4)\n",
        "                    ax.tick_params(axis='both', which='both', left=False, bottom=False, labelleft=False, labelbottom=False)\n",
        "                    for spine in ax.spines.values():\n",
        "                        spine.set_visible(False)\n",
        "    # plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05, hspace=0.1, wspace=0.05)  # Adjust overall spacing\n",
        "    \"\"\"\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "jwv-9xJ3xOQC"
      },
      "id": "jwv-9xJ3xOQC",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -n 1 -r 1\n",
        "for _ in range(1000):\n",
        "  image = spatialized_gt(ndiscs=4, size=64, pseudo_size=172, nsteps=12, stratification='occurrence', centered=True, freq_occurrence=f)\n",
        "  i += image[:,1].max()>0\n",
        "  # print(image[:,1].max()>0)\n",
        "print(i/1000)"
      ],
      "metadata": {
        "id": "hXF7Oa5ib4km"
      },
      "id": "hXF7Oa5ib4km",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S = 172\n",
        "# in the dataset :\n",
        "# image = spatialized_gt(ndiscs=4, size=S, nsteps=12)\n",
        "# image = spatialized_gt(ndiscs=4, size=64, pseudo_size=172, nsteps=12, stratification='occurrence', centered=True, freq_reports=0.01)\n",
        "image, reports = spatialized_gt(ndiscs=4, size=172, pseudo_size=172, nsteps=12, stratification=None, centered=False, freq_reports=0.01)\n",
        "device = torch.device('cpu')\n",
        "images = torch.tensor(image).unsqueeze(0).float().to(device)\n",
        "\n",
        "\n",
        "plot_images(image, reports.repeat(), 0)\n"
      ],
      "metadata": {
        "id": "AsxEdMv_ubkS"
      },
      "id": "AsxEdMv_ubkS",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}